from langchain_core.messages import BaseMessage

from langchain_core.prompts import (
    ChatPromptTemplate,
    HumanMessagePromptTemplate,
    SystemMessagePromptTemplate,
)

from langchain_openai import ChatOpenAI

from shared.models.chatgpt_vector_graphdb_qa_parameters import (
    ChatgptVectorGraphdbQaParameters,
)

from pydantic import ValidationError
import logging
import os


class ChatgptVectorGraphdbQA:
    """
    Defines a ChatGPT-based question-answering system integrated with vector representations and a graph database.

    Attributes:
    _logger : Logger
        The logger instance for the service.
    parameters : ChatgptVectorGraphdbQaParameters
        Configuration parameters for the ChatGPT, vector, and graph database integration.
    chat : ChatOpenAI
        ChatOpenAI instance for generating AI responses.
    chat_prompt : ChatPromptTemplate
        Template for creating prompts including system and human messages.
    """

    def __init__(self, app_config) -> None:
        """Initializes the ChatgptVectorGraphdbQA."""
        self._logger = logging.getLogger(__name__)

        # Validate and set configuration parameters
        if not isinstance(app_config, dict):
            self._logger.critical(
                msg="The configuration given to the service is not of dict type."
            )
            raise RuntimeError("Bad Config Type")

        try:
            self.parameters = ChatgptVectorGraphdbQaParameters(**app_config)
        except ValidationError as e:
            self._logger.critical(
                exc_info=True,
                msg=f"Faulty parameter into the db client's configuration : {e}.",
            )
            raise RuntimeError("Bad Config Parameter") from e

        os.environ["OPENAI_API_KEY"] = self.parameters.openai_api_key

        # Initialize ChatOpenAI instance with specified parameters
        self.chat = ChatOpenAI(temperature=0, model=self.parameters.openai_model)

        # Construct chat prompt template from system and human messages
        self.chat_prompt = ChatPromptTemplate.from_messages(
            [
                SystemMessagePromptTemplate.from_template(
                    self.parameters.system_prompt
                ),
                HumanMessagePromptTemplate.from_template(self.parameters.human_prompt),
            ]
        )

    def answer_question(
        self, question: str, vector_answer: str, graphdb_answer: str
    ) -> str:
        """
        Answers a given question using ChatGPT, vector representation, and graph database.

        Parameters:
        question (str): The question to be answered.
        vector_answer (str): Answer obtained from vector representation.
        graphdb_answer (str): Answer obtained from the graph database.

        Returns:
        str: The response generated by the ChatGPT model.

        Raises:
        RuntimeError: If an error occurs during the question-answering process.
        """
        try:
            # Format and invoke the chat with the provided prompts
            return str(
                self.chat.invoke(
                    self.chat_prompt.format_prompt(
                        question=question,
                        vector_answer=vector_answer,
                        graphdb_answer=graphdb_answer,
                    ).to_messages()
                )
            )
        except Exception as e:
            # Log and raise error if invocation fails
            self._logger.error(
                "An error occurred while invoking the chain with ChatGPT, Neo4j vector, and GraphDB: %s",
                e,
                exc_info=True,
            )
            raise RuntimeError
